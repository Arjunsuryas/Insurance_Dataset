def classification_metrics(y_true, y_pred):
    return {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred),
        'f1': f1_score(y_true, y_pred)
    }

# Logistic Regression
log_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))
])
log_pipeline.fit(X_train, y_clf_train)
y_log_pred = log_pipeline.predict(X_test)
log_results = classification_metrics(y_clf_test, y_log_pred)
print("Logistic Regression results:", log_results)
print("\nClassification Report:\n", classification_report(y_clf_test, y_log_pred))

# Random Forest Classifier
rfc_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))
])
param_grid_rfc = {
    'classifier__n_estimators': [100],
    'classifier__max_depth': [8, None]
}
grid_rfc = GridSearchCV(rfc_pipeline, param_grid_rfc, cv=3, scoring='f1')
grid_rfc.fit(X_train, y_clf_train)
best_rfc = grid_rfc.best_estimator_
y_rfc_pred = best_rfc.predict(X_test)
rfc_results = classification_metrics(y_clf_test, y_rfc_pred)
print("Random Forest Classifier results:", rfc_results)

# Confusion Matrix
cm = confusion_matrix(y_clf_test, y_rfc_pred)
plt.imshow(cm, cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.colorbar()
for i in range(2):
    for j in range(2):
        plt.text(j, i, cm[i,j], ha="center", va="center", color="white")
plt.show()
